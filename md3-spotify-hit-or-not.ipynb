{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0e8b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib notebook\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb65e9",
   "metadata": {},
   "source": [
    "Idea:\n",
    "    JUNTAR TOTS ELS DATASETS EN 1 DE SOL AMB UN NOU ATRIBUT QUE SIGUI LA DECADA. Deixar la ultima o ultimes decades per dades de test. o si no agafar tant percent de cada decada per test. Primer probare agafant les decades de 60 fins a 90 per a train i deixare el 2000 i 2010 com a test.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7cc2d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decade              0\n",
      "danceability        0\n",
      "energy              0\n",
      "key                 0\n",
      "loudness            0\n",
      "mode                0\n",
      "speechiness         0\n",
      "acousticness        0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "valence             0\n",
      "tempo               0\n",
      "duration_ms         0\n",
      "time_signature      0\n",
      "chorus_hit          0\n",
      "sections            0\n",
      "target              0\n",
      "dtype: int64\n",
      "Dimensionalitat de la BBDD: (41106, 17)\n",
      "Dimensionalitat de les entrades X (18499, 17)\n",
      "Dimensionalitat de l'atribut Y (18499,)\n"
     ]
    }
   ],
   "source": [
    "from src.generate_features import *\n",
    "\n",
    "# Visualitzarem nom√©s 3 decimals per mostra\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "dataset_train, dataset_test, dataset_validate, dataset_full = generate_dataset(type='non-nlp')\n",
    "\n",
    "data = dataset_test.values\n",
    "target = dataset_test.target\n",
    "\n",
    "x = data[:, :18]\n",
    "y = target\n",
    "\n",
    "print(\"Dimensionalitat de la BBDD:\", dataset_full.shape)\n",
    "print(\"Dimensionalitat de les entrades X\", x.shape)\n",
    "print(\"Dimensionalitat de l'atribut Y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42553cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per comptar el nombre de valors no existents:\n",
      "decade              0\n",
      "danceability        0\n",
      "energy              0\n",
      "key                 0\n",
      "loudness            0\n",
      "mode                0\n",
      "speechiness         0\n",
      "acousticness        0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "valence             0\n",
      "tempo               0\n",
      "duration_ms         0\n",
      "time_signature      0\n",
      "chorus_hit          0\n",
      "sections            0\n",
      "target              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Per comptar el nombre de valors no existents:\")\n",
    "print(dataset_full.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "792f1428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per comptar el nombre de cancons per artistes:\n",
      "[0.515 0.697 0.662 ... 0.612 0.719 0.6]\n"
     ]
    }
   ],
   "source": [
    "print(\"Per comptar el nombre de cancons per artistes:\")\n",
    "print(x[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b84a69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per visualitzar les primeres 5 mostres de la BBDD:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decade</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>chorus_hit</th>\n",
       "      <th>sections</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.620</td>\n",
       "      <td>3</td>\n",
       "      <td>-7.727</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.845</td>\n",
       "      <td>185.655</td>\n",
       "      <td>173533</td>\n",
       "      <td>3</td>\n",
       "      <td>32.950</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1960</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.505</td>\n",
       "      <td>3</td>\n",
       "      <td>-12.475</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.797</td>\n",
       "      <td>101.801</td>\n",
       "      <td>213613</td>\n",
       "      <td>4</td>\n",
       "      <td>48.825</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1960</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.649</td>\n",
       "      <td>5</td>\n",
       "      <td>-13.392</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.908</td>\n",
       "      <td>115.940</td>\n",
       "      <td>223960</td>\n",
       "      <td>4</td>\n",
       "      <td>37.227</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.545</td>\n",
       "      <td>7</td>\n",
       "      <td>-12.058</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.967</td>\n",
       "      <td>105.592</td>\n",
       "      <td>157907</td>\n",
       "      <td>4</td>\n",
       "      <td>24.755</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.765</td>\n",
       "      <td>11</td>\n",
       "      <td>-3.515</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.906</td>\n",
       "      <td>114.617</td>\n",
       "      <td>245600</td>\n",
       "      <td>4</td>\n",
       "      <td>21.799</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  decade  danceability  energy  key  loudness  mode  speechiness  \\\n",
       "0   1960         0.417   0.620    3    -7.727     1        0.040   \n",
       "1   1960         0.498   0.505    3   -12.475     1        0.034   \n",
       "2   1960         0.657   0.649    5   -13.392     1        0.038   \n",
       "3   1960         0.590   0.545    7   -12.058     0        0.104   \n",
       "4   1960         0.515   0.765   11    -3.515     0        0.124   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  valence   tempo  duration_ms  \\\n",
       "0         0.490             0.000     0.078    0.845 185.655       173533   \n",
       "1         0.018             0.107     0.176    0.797 101.801       213613   \n",
       "2         0.846             0.000     0.119    0.908 115.940       223960   \n",
       "3         0.706             0.025     0.061    0.967 105.592       157907   \n",
       "4         0.857             0.001     0.213    0.906 114.617       245600   \n",
       "\n",
       "   time_signature  chorus_hit  sections  target  \n",
       "0               3      32.950         9       1  \n",
       "1               4      48.825        10       0  \n",
       "2               4      37.227        12       0  \n",
       "3               4      24.755         8       0  \n",
       "4               4      21.799        14       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Per visualitzar les primeres 5 mostres de la BBDD:\")\n",
    "dataset_full.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e9ab09",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Primer vaig comen√ßar per probar diferents models estadistics classificadors per veure quin hem donava millor resultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c8991a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elblo\\Desktop\\Universidad\\3r A√±o\\1r Semestre\\APC\\Kaggle\\MD3 Spotify\\src\\train_model.py:19: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  x_train = dataset_train.drop(['target'], 1).values  # values converts it into a numpy array\n",
      "c:\\Users\\elblo\\Desktop\\Universidad\\3r A√±o\\1r Semestre\\APC\\Kaggle\\MD3 Spotify\\src\\train_model.py:22: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  x_test = dataset_test.drop(['target'], 1).values  # values converts it into a numpy array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "Logistic Regression\n",
      "###\n",
      "Logistic Regression trained.\n",
      "###\n",
      "K-Nearest Neighbors\n",
      "###\n",
      "K-Nearest Neighbors trained.\n",
      "###\n",
      "Decision Tree\n",
      "###\n",
      "Decision Tree trained.\n",
      "###\n",
      "Support Vector Machine (Linear Kernel)\n",
      "###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elblo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine (Linear Kernel) trained.\n",
      "###\n",
      "Random Forest\n",
      "###\n",
      "Random Forest trained.\n",
      "###\n",
      "Naive Bayes\n",
      "###\n",
      "Naive Bayes trained.\n",
      "###\n",
      "Neural Net\n",
      "###\n",
      "Neural Net trained.\n",
      "###\n",
      "AdaBoost\n",
      "###\n",
      "AdaBoost trained.\n",
      "###\n",
      "Gradient Boosting\n",
      "###\n",
      "Gradient Boosting trained.\n",
      "Logistic Regression: 50.80%\n",
      "###\n",
      "Model evaluation Logistic Regression\n",
      "###\n",
      "Accuracy: 50.7973403967782\n",
      "Precision: 50.60750132065505\n",
      "Recall: 62.20779220779221\n",
      "F1 score: 0.5581124381007865\n",
      "Training MSE:  0.48620951801733314\n",
      "Test model MSE 0.49202659603221793\n",
      "K-Nearest Neighbors: 57.08%\n",
      "###\n",
      "Model evaluation K-Nearest Neighbors\n",
      "###\n",
      "Accuracy: 57.08416671171415\n",
      "Precision: 56.519995990778796\n",
      "Recall: 61.028138528138534\n",
      "F1 score: 0.586876203361607\n",
      "Training MSE:  0.21444427550554965\n",
      "Test model MSE 0.42915833288285854\n",
      "Decision Tree: 71.43%\n",
      "###\n",
      "Model evaluation Decision Tree\n",
      "###\n",
      "Accuracy: 71.42548245851127\n",
      "Precision: 71.23523093447905\n",
      "Recall: 71.77489177489178\n",
      "F1 score: 0.7150404312668464\n",
      "Training MSE:  0.00012163600425726015\n",
      "Test model MSE 0.2857451754148873\n",
      "Support Vector Machine (Linear Kernel): 50.05%\n",
      "###\n",
      "Model evaluation Support Vector Machine (Linear Kernel)\n",
      "###\n",
      "Accuracy: 50.05135412725012\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elblo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE:  0.5006537935228828\n",
      "Test model MSE 0.4994864587274988\n",
      "Random Forest: 79.99%\n",
      "###\n",
      "Model evaluation Random Forest\n",
      "###\n",
      "Accuracy: 79.98810746526838\n",
      "Precision: 77.37247924080664\n",
      "Recall: 84.70779220779221\n",
      "F1 score: 0.8087414755114695\n",
      "Training MSE:  0.0001520450053215752\n",
      "Test model MSE 0.20011892534731607\n",
      "Naive Bayes: 62.09%\n",
      "###\n",
      "Model evaluation Naive Bayes\n",
      "###\n",
      "Accuracy: 62.08984269419968\n",
      "Precision: 57.4576384702967\n",
      "Recall: 92.84632034632034\n",
      "F1 score: 0.7098589218484961\n",
      "Training MSE:  0.37360498707617457\n",
      "Test model MSE 0.3791015730580031\n",
      "Neural Net: 64.18%\n",
      "###\n",
      "Model evaluation Neural Net\n",
      "###\n",
      "Accuracy: 64.18184766744149\n",
      "Precision: 61.2517217630854\n",
      "Recall: 77.0021645021645\n",
      "F1 score: 0.6822976601457614\n",
      "Training MSE:  0.34812224418427856\n",
      "Test model MSE 0.35818152332558517\n",
      "AdaBoost: 76.24%\n",
      "###\n",
      "Model evaluation AdaBoost\n",
      "###\n",
      "Accuracy: 76.24195902481216\n",
      "Precision: 73.16630008606676\n",
      "Recall: 82.8030303030303\n",
      "F1 score: 0.7768695740468091\n",
      "Training MSE:  0.2190056256651969\n",
      "Test model MSE 0.23758040975187847\n",
      "Gradient Boosting: 78.77%\n",
      "###\n",
      "Model evaluation Gradient Boosting\n",
      "###\n",
      "Accuracy: 78.76641980647602\n",
      "Precision: 75.08026440037771\n",
      "Recall: 86.04978354978356\n",
      "F1 score: 0.8019162884518407\n",
      "Training MSE:  0.19039075566367644\n",
      "Test model MSE 0.21233580193523974\n"
     ]
    }
   ],
   "source": [
    "from src.train_model import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_train_test(dataset_train, dataset_test, dataset_validate)\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Support Vector Machine (Linear Kernel)\": LinearSVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Neural Net\": MLPClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(\"###\")\n",
    "    print(name)\n",
    "    print(\"###\")\n",
    "    model.fit(x_train, y_train)\n",
    "    print(name + \" trained.\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(name + \": {:.2f}%\".format(model.score(x_test, y_test) * 100))\n",
    "    print(\"###\")\n",
    "    print(\"Model evaluation {0}\".format(name))\n",
    "    print(\"###\")\n",
    "    evaluate_model(x_train, x_test, y_train, y_test, model.predict(x_test), model)\n",
    "    # print(\"###\")\n",
    "    # print(\"Cross validation {0}\".format(name))\n",
    "    # print(\"###\")\n",
    "    # cross_val_preds = cross_val_predict(model, x_val, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1287183",
   "metadata": {},
   "source": [
    "Com podem veure, el model de Random Forest ens retorna l'accuracy mes alt. Per tant haurem de treballar amb aquest. El seguent que volia veure era buscar quines variables ens ajuden a diferenciar entre HIT i no HIT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d127e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create two var lists, one with Spotify's features (spfeatures_var_list) and one with the song traits (song_traits_var_list)\n",
    "spfeatures_var_list = ['danceability', 'energy', 'key', 'loudness','mode', 'speechiness', 'acousticness', \n",
    "                       'instrumentalness', 'liveness','valence']\n",
    "song_traits_var_list = ['key', 'loudness','tempo', 'time_signature', 'chorus_hit','sections'] \n",
    "#duration_ms has been removed since it has such larger numbers than the other variables \n",
    "\n",
    "all_songs_hits = dataset_train[spfeatures_var_list].loc[dataset_train['target'] == 1]\n",
    "\n",
    "all_songs_flops = dataset_train[spfeatures_var_list].loc[dataset_train['target'] == 0]\n",
    "\n",
    "#create a dataframe that includes the means for hits and flops\n",
    "hits_means = pd.DataFrame(all_songs_hits.describe().loc['mean'])\n",
    "flops_means = pd.DataFrame(all_songs_flops.describe().loc['mean'])\n",
    "means_joined = pd.concat([hits_means,flops_means], axis = 1)\n",
    "means_joined.columns = ['hit_mean', 'flop_mean']\n",
    "\n",
    "ss = StandardScaler()\n",
    "means_joined_scaled = pd.DataFrame(ss.fit_transform(means_joined),index= means_joined.index, columns = means_joined.columns)\n",
    "means_joined_scaled\n",
    "\n",
    "\n",
    "means_joined_scaled.plot(kind = 'bar', figsize=(10, 5), color = ('purple', 'grey'), title = 'Means of Hit Songs and Flop Songs for Song Features')\n",
    "plt.legend(labels=['Hits', 'Flops'], loc='upper right')\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8369fc",
   "metadata": {},
   "source": [
    "Anem a veure l'histograma de cada variable per buscar les distribucions de les nostres variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c3d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create histograpms of all the variables to see distributions\n",
    "fig, ax = plt.subplots(5,3, figsize=(5,5))\n",
    "\n",
    "def hist_plot(row, column, variable, binsnum, color):\n",
    "    ax[row, column].hist(dataset_train[variable], bins = binsnum, color = color)\n",
    "    ax[row, column].set_title(variable + ' histogram')\n",
    "    \n",
    "hist_plot(0, 0, 'danceability', 10, 'purple')\n",
    "hist_plot(0, 1, 'energy', 10, 'orchid')\n",
    "hist_plot(0, 2, 'key', 10, 'plum')\n",
    "hist_plot(1,0, 'loudness', 10, 'purple')\n",
    "hist_plot(1,1, 'mode', 10, 'orchid')\n",
    "hist_plot(1,2, 'speechiness', 10, 'plum')\n",
    "hist_plot(2,0, 'acousticness', 10, 'purple')\n",
    "hist_plot(2,1, 'instrumentalness', 10, 'orchid')\n",
    "hist_plot(2,2, 'liveness', 10, 'plum')\n",
    "hist_plot(3,0, 'valence', 10, 'purple')\n",
    "hist_plot(3,1, 'tempo', 10, 'orchid')\n",
    "hist_plot(3,2, 'duration_ms', 50, 'plum')\n",
    "hist_plot(4,0, 'time_signature', 10, 'purple')\n",
    "hist_plot(4,1, 'chorus_hit', 10, 'orchid')\n",
    "hist_plot(4,2, 'sections', 50, 'plum')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b78cf",
   "metadata": {},
   "source": [
    "Aqu√≠ hi ha alguns patrons interessants: les can√ßons solen ser m√©s ballables que menys ballables, les can√ßons tendeixen a tenir m√©s energia que menys energia, la tonalitat de C √©s la tonalitat m√©s popular, les can√ßons solen ser inferiors a 10 decibels, la majoria de les can√ßons estan en escales majors, la majoria de les can√ßons contenen m√©s m√∫sica que la parla, la majoria de les can√ßons no s√≥n en directe, la majoria de les can√ßons no s√≥n ac√∫stiques, la majoria de les can√ßons contenen m√∫sica, hi ha una bona barreja de can√ßons alegres i tristes, la majoria de can√ßons tenen uns 80-90 pulsacions per minut i la majoria de can√ßons s√≥n en 4/4 de temps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2514f246",
   "metadata": {},
   "source": [
    "Anem a crear un model de random forest i provar rendiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb63ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier()\n",
    "RF.fit(x_train, y_train)\n",
    "y_pred = RF.predict(x_test)\n",
    "\n",
    "#create a confusion matrix to see the efficacy of the model\n",
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix\n",
    "\n",
    "#create a figure/heatmap of the confusion matrix for a better visual\n",
    "mpl.rcParams['figure.figsize']=(10,5)\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"RdPu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc8f5d",
   "metadata": {},
   "source": [
    "The confusion matrix demonstrates that the model correctly identified hits and flops most of the time. \n",
    "Podem observar com al pas de les decades, com de importants son cara atribut de les can√ßons ja que possiblement depenent de la decada, li donaven mes importancia potser al tant per cetn de ballable  i no tant al tant percent de instrumentabilitat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864d1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe of the feature importances to determine which variables are the most important in determining a hit\n",
    "all_songs_feat = RF.feature_importances_\n",
    "df_indep_columns = pd.DataFrame(indep_columns)\n",
    "df_all_songs_feat = pd.DataFrame(all_songs_feat)\n",
    "all_songs_feat_vars = pd.concat([df_indep_columns, df_all_songs_feat], axis = 1)\n",
    "all_songs_feat_vars.columns = ['Variable', 'Feature importance all decades']\n",
    "all_songs_feat_vars = all_songs_feat_vars.set_index('Variable')\n",
    "all_songs_feat_vars = all_songs_feat_vars.sort_values(by=['Feature importance all decades'], ascending = False)\n",
    "all_songs_feat_vars\n",
    "all_songs_feat_vars.to_csv('all_songs_feat.csv', index = False) #create a CSV file of the new dataframe\n",
    "\n",
    "all_songs_feat_vars.plot(kind='bar', color = \"purple\", title = \"Most important features for predicting hit and flop songs for all decades\", legend = None)\n",
    "plt.ylabel('Feature importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd4c452",
   "metadata": {},
   "source": [
    "For all decades, instrumentalness, danceability, acousticness, duration_ms, and loudness were the greatest predictors of if a song was a hit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f3bfdf",
   "metadata": {},
   "source": [
    "# Proves amb NLP (NLTK)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
